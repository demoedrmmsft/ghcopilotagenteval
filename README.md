# ğŸ¤– GitHub Copilot Agent: DataStage â†’ Databricks Migration

Un agente declarativo de GitHub Copilot especializado en migrar jobs de IBM DataStage a Azure Databricks, generando cÃ³digo PySpark optimizado, notebooks Databricks completos y siguiendo mejores prÃ¡cticas de ingenierÃ­a de datos.

> **Tipo de Agente**: GitHub Copilot Agent (Declarativo con `agent.yml`)  
> **Sin servidor requerido** - Funciona directamente en VS Code

[![GitHub Copilot](https://img.shields.io/badge/GitHub%20Copilot-Agent-blue?logo=github)](https://github.com/features/copilot)
[![Databricks](https://img.shields.io/badge/Databricks-Ready-orange?logo=databricks)](https://databricks.com)
[![PySpark](https://img.shields.io/badge/PySpark-3.x-yellow?logo=apache-spark)](https://spark.apache.org/pyspark.html)

---

## ğŸ“‘ Tabla de Contenido

- [CaracterÃ­sticas](#caracterÃ­sticas)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [InstalaciÃ³n RÃ¡pida](#instalaciÃ³n)
- [CÃ³mo Usar el Agente](#cÃ³mo-usar-el-agente)
- [Ejemplos de Uso](#ejemplos-de-uso)
- [Capacidades del Agente](#capacidades-del-agente)
- [GuÃ­as Detalladas](#guÃ­as-detalladas)
- [Troubleshooting](#troubleshooting)
- [Contribuir](#contribuir)
- [Testing y ValidaciÃ³n](#testing-y-validaciÃ³n)
- [Mejores PrÃ¡cticas](#mejores-prÃ¡cticas)
- [Troubleshooting](#troubleshooting)
- [Contribuir](#contribuir)

---

## ğŸ¯ CaracterÃ­sticas

### AnÃ¡lisis Inteligente de Jobs DataStage
- âœ… Parsea archivos DSX (XML de DataStage)
- âœ… Identifica tipos de stages (Sequential File, Transformer, Join, Aggregator, etc.)
- âœ… Mapea flujo de datos entre stages
- âœ… Extrae transformaciones, filtros y lÃ³gica de negocio

### GeneraciÃ³n de CÃ³digo PySpark Optimizado
- âœ… Traduce stages DataStage a operaciones PySpark equivalentes
- âœ… Implementa transformaciones complejas (derivations, constraints)
- âœ… Convierte lÃ³gica BASIC de DataStage a Python/PySpark
- âœ… Optimiza para procesamiento distribuido
- âœ… Implementa error handling robusto

### Notebooks Databricks Estructurados
- âœ… Notebooks bien documentados con markdown
- âœ… Widgets para parÃ¡metros configurables
- âœ… Logging y monitoreo integrado
- âœ… Validaciones de calidad de datos
- âœ… Tests unitarios sugeridos

### Mejores PrÃ¡cticas
- âœ… Aprovecha Delta Lake para ACID transactions
- âœ… Implementa particionamiento eficiente
- âœ… Usa broadcast joins inteligentemente
- âœ… Aplica optimizaciones de Spark (AQE, caching, etc.)
- âœ… Maneja errores y rechazos apropiadamente

---

## ğŸ“ Estructura del Proyecto

```
agentcopiloteval/
â”œâ”€â”€ agent.yml                            # â­ ConfiguraciÃ³n del agente (declarativa)
â”œâ”€â”€ README.md                            # Este archivo
â”œâ”€â”€ knowledge/                           # Base de conocimiento del agente
â”‚   â”œâ”€â”€ datastage-components.md         # CatÃ¡logo completo de stages
â”‚   â”œâ”€â”€ migration-patterns.md           # Patrones con cÃ³digo completo
â”‚   â”œâ”€â”€ databricks-best-practices.md    # Optimizaciones Databricks
â”‚   â””â”€â”€ quick-migration-guide.md        # GuÃ­a paso a paso
â”œâ”€â”€ test-artifacts/                      # Jobs DataStage de prueba (.dsx)
â”‚   â”œâ”€â”€ 01_simple_customer_etl.dsx      # ETL bÃ¡sico
â”‚   â”œâ”€â”€ 02_order_processing_join.dsx    # Joins y agregaciones
â”‚   â”œâ”€â”€ 03_scd_type2_dimension.dsx      # SCD Type 2
â”‚   â”œâ”€â”€ 04_validation_error_handling.dsx # Manejo de errores
â”‚   â””â”€â”€ README.md                        # DocumentaciÃ³n de casos
â””â”€â”€ examples/                            # Notebooks Databricks de ejemplo
    â””â”€â”€ sample_migrated_notebook.py      # Ejemplo completo migrado
```

### Archivos Clave

- **`agent.yml`**: ConfiguraciÃ³n declarativa del agente con instrucciones, capacidades, y referencias a knowledge base
- **`knowledge/*.md`**: Base de conocimiento con patrones, componentes, y mejores prÃ¡cticas
- **`test-artifacts/*.dsx`**: Jobs de ejemplo para validar el agente
- **`examples/`**: Notebooks Databricks ya migrados como referencia

---

## ğŸš€ CÃ³mo Usar el Agente

### Requisitos Previos

1. **GitHub Copilot** instalado y activado en VS Code
2. **VS Code** versiÃ³n reciente
3. Este **workspace abierto** en VS Code

### Setup RÃ¡pido

```bash
# 1. Clona el repositorio
git clone https://github.com/your-org/datastage-migration-agent.git
cd datastage-migration-agent

# 2. Abre en VS Code
code .

# 3. Â¡Listo! El agente se carga automÃ¡ticamente desde agent.yml
```

### MÃ©todo 1: MigraciÃ³n Directa (Archivo .dsx)

1. **Abre GitHub Copilot Chat**: `Ctrl+Shift+I` (Windows/Linux) o `Cmd+Shift+I` (Mac)

2. **Invoca el agente** con `@workspace`:

```
@workspace Migra el job test-artifacts/01_simple_customer_etl.dsx a Databricks
```

3. **El agente genera**:
   - âœ… AnÃ¡lisis del job (stages, flujo de datos, parÃ¡metros)
   - ğŸ““ Notebook Databricks completo con cÃ³digo PySpark
   - ğŸ’¡ Recomendaciones de optimizaciÃ³n especÃ­ficas
   - ğŸ“ PrÃ³ximos pasos de implementaciÃ³n

### MÃ©todo 2: AnÃ¡lisis sin MigraciÃ³n

Para solo analizar complejidad y obtener estimaciones:

### MÃ©todo 2: AnÃ¡lisis sin MigraciÃ³n

Para solo analizar complejidad y obtener estimaciones:

```
@workspace Analiza la complejidad del job test-artifacts/03_scd_type2_dimension.dsx
```

**El agente responde con**:
- Nivel de complejidad: Low, Medium, High, Very High
- EstimaciÃ³n de esfuerzo en horas
- Lista de stages y tipos
- DesafÃ­os potenciales identificados
- Recomendaciones de abordaje

### MÃ©todo 3: Consultas sobre Componentes

Para entender componentes DataStage y sus equivalentes:

```
@workspace Explica cÃ³mo migrar un stage Aggregator a PySpark
```

```
@workspace Â¿CÃ³mo implemento SCD Type 2 en Databricks?
```

```
@workspace Dame un ejemplo de traducir expresiones BASIC a PySpark
```
3. Calcular LineTotal = Quantity * UnitPrice
4. Agregar por Cliente y Mes:
   - Total Orders
   - Revenue Total
   - Avg Order Value
5. Filtrar solo Ã³rdenes completadas
6. Ordenar por Revenue descendente

**Output:**
- Delta Lake table particionada por aÃ±o/mes

Incluye validaciones de calidad de datos y error handling.
```

### MÃ©todo 3: Migrar desde Test Artifacts

Usa los jobs de ejemplo incluidos:

```
@workspace Migra el job test-artifacts/02_order_processing_join.dsx 
a Databricks con todas las optimizaciones recomendadas
```

---

## ğŸ’¡ Ejemplos de Uso

### Ejemplo 1: ETL Simple

**Prompt**:
```
@workspace Migra el job test-artifacts/01_simple_customer_etl.dsx
```

**El agente generarÃ¡**:
- Notebook con:
  - Lectura de CSV con spark.read
  - Transformaciones con withColumn()
  - Limpieza de datos (trim, upper, null handling)
  - Escritura a Delta Lake
  - Validaciones

### Ejemplo 2: Joins y Aggregations

**Prompt**:
```
@workspace Analiza y migra test-artifacts/02_order_processing_join.dsx
Optimiza especialmente los joins y explain las decisiones.
```

**El agente generarÃ¡**:
- AnÃ¡lisis de cada join (inner, lookup)
- CÃ³digo con broadcast join para tabla pequeÃ±a
- Aggregations con groupBy().agg()
- ExplicaciÃ³n de por quÃ© eligiÃ³ broadcast vs shuffle join

### Ejemplo 3: SCD Type 2

**Prompt**:
```
@workspace Migra test-artifacts/03_scd_type2_dimension.dsx
Usa Delta Lake merge operations para implementar SCD Type 2
```

**El agente generarÃ¡**:
- ImplementaciÃ³n con DeltaTable.merge()
- LÃ³gica para cerrar registros antiguos
- InserciÃ³n de nuevas versiones
- Manejo de Effective/End dates e IsCurrent flags

### Ejemplo 4: Error Handling

**Prompt**:
```
@workspace Migra test-artifacts/04_validation_error_handling.dsx
AsegÃºrate de manejar todos los errores y generar logs detallados
```

**El agente generarÃ¡**:
- DataFrames separados para buenos y malos registros
- Validaciones implementadas con filter()
- Metadata de errores agregada
- Logging comprehensivo

### Ejemplo 5: OptimizaciÃ³n de Job Existente

**Prompt**:
```
@workspace Tengo este notebook Databricks [pegar cÃ³digo]
que fue migrado desde DataStage pero es muy lento.
AnalÃ­zalo y sugiere optimizaciones.
```

**El agente analizarÃ¡**:
- Joins y sugerirÃ¡ broadcast donde apropiado
- Particionamiento y sugerirÃ¡ repartition
- Shuffles innecesarios
- Oportunidades de caching
- Configuraciones de Spark

---

## ğŸ“ Capacidades del Agente

### 1. TraducciÃ³n de Stages DataStage

| DataStage Stage | PySpark Equivalent | Agente Implementa |
|----------------|-------------------|-------------------|
| Sequential File | `spark.read.csv()` | âœ… Con todas las opciones |
| Transformer | `withColumn()`, `filter()` | âœ… Con expresiones complejas |
| Join | `join()` | âœ… Con estrategia optimizada |
| Lookup | `broadcast(df).join()` | âœ… Auto-detecta tablas pequeÃ±as |
| Aggregator | `groupBy().agg()` | âœ… Con todas las funciones |
| Sort | `orderBy()` | âœ… Con mÃºltiples keys |
| Remove Duplicates | `dropDuplicates()` | âœ… Con subset de columnas |
| Change Capture | Delta CDC | âœ… Con merge operations |
| Funnel | `union()` | âœ… Con unionByName |

### 2. TraducciÃ³n de Expresiones BASIC

El agente traduce automÃ¡ticamente:

```basic
# DataStage BASIC
If IsNull(Column1) Then "DEFAULT" Else Column1
Trim(Upcase(FirstName)) : " " : Trim(Upcase(LastName))
Column1[1,10]
YearsFromDate(BirthDate)
```

```python
# PySpark generado por el agente
F.when(F.col("Column1").isNull(), F.lit("DEFAULT")).otherwise(F.col("Column1"))
F.concat(F.trim(F.upper("FirstName")), F.lit(" "), F.trim(F.upper("LastName")))
F.substring("Column1", 1, 10)
F.floor(F.months_between(F.current_date(), F.col("BirthDate")) / 12)
```

### 3. Optimizaciones AutomÃ¡ticas

El agente aplica:

- âœ… **Broadcast Joins**: Para tablas pequeÃ±as (<10GB)
- âœ… **Particionamiento**: Basado en keys y volumen de datos
- âœ… **Delta Lake**: Para todas las tablas intermedias
- âœ… **AQE (Adaptive Query Execution)**: Habilitado por default
- âœ… **Z-Ordering**: Para queries con filtros comunes
- âœ… **Caching**: Para DataFrames reutilizados

### 4. Patrones Avanzados

El agente maneja:

- âœ… **SCD Type 2**: Con Delta merge y lÃ³gica de versionado
- âœ… **Change Data Capture**: DetecciÃ³n de cambios
- âœ… **Error Handling**: Reject links â†’ DataFrames separados
- âœ… **Stage Variables**: Convertidos a window functions o columnas temporales
- âœ… **Complex Constraints**: MÃºltiples validaciones con metadata de errores

---

## ğŸ§ª Testing y ValidaciÃ³n

### Usar Test Artifacts

El proyecto incluye 4 jobs DataStage de ejemplo:

```bash
test-artifacts/
â”œâ”€â”€ 01_simple_customer_etl.dsx           # BÃ¡sico
â”œâ”€â”€ 02_order_processing_join.dsx         # Joins
â”œâ”€â”€ 03_scd_type2_dimension.dsx           # SCD
â””â”€â”€ 04_validation_error_handling.dsx     # Errors
```

### Proceso de ValidaciÃ³n

1. **Migrar con el agente**:
```
@workspace Migra test-artifacts/01_simple_customer_etl.dsx
```

2. **Copiar cÃ³digo a Databricks notebook**

3. **Ejecutar con datos de prueba**

4. **Validar output**:
```python
# Comparar counts
print(f"Records: {df_output.count()}")

# Verificar schema
df_output.printSchema()

# Revisar sample
display(df_output.limit(10))

# Validaciones de calidad
null_counts = df_output.select(
    *[F.sum(F.col(c).isNull().cast("int")).alias(c) 
      for c in df_output.columns]
).collect()[0].asDict()

for col, nulls in null_counts.items():
    if nulls > 0:
        print(f"âš ï¸ {col}: {nulls} nulls")
```

### Checklist de ValidaciÃ³n

Para cada migraciÃ³n, verificar:

- [ ] ğŸ¯ **Funcionalidad**: Todas las transformaciones migradas
- [ ] ğŸ“Š **Output Correcto**: Counts y samples coinciden con expectativa
- [ ] âš¡ **Performance**: Tiempo de ejecuciÃ³n aceptable
- [ ] ğŸ›¡ï¸ **Error Handling**: Rechazos manejados apropiadamente
- [ ] ğŸ“ **DocumentaciÃ³n**: CÃ³digo bien comentado y explicado
- [ ] ğŸ”§ **Optimizaciones**: Broadcast, partitioning aplicados
- [ ] âœ… **Validaciones**: Data quality checks implementados

---

## ğŸ“š Mejores PrÃ¡cticas

### 1. PreparaciÃ³n

**Antes de migrar, reunir**:
- Archivo DSX exportado desde DataStage
- DescripciÃ³n del job y su propÃ³sito
- Volumen tÃ­pico de datos
- Requisitos de performance (SLAs)
- Jobs upstream/downstream (dependencias)

### 2. IteraciÃ³n

**Proceso recomendado**:
1. Migrar funcionalidad primero (hacer que funcione)
2. Validar con datos de prueba
3. Optimizar performance
4. Agregar monitoring y alerts
5. Documentar

### 3. ComparaciÃ³n con DataStage

**Para validar migraciÃ³n**:
```python
# Ejecutar DataStage job con test data
# Capturar output

# Ejecutar notebook Databricks con mismo input
# Comparar outputs:

# - Counts
# - Checksums de columnas numÃ©ricas
# - Sample de registros
# - Schema (tipos de datos)
```

### 4. Monitoreo Post-MigraciÃ³n

**Implementar**:
```python
# MÃ©tricas de ejecuciÃ³n
metrics = {
    "job_name": "migrated_job",
    "start_time": start_time,
    "end_time": end_time,
    "duration_sec": duration,
    "records_input": input_count,
    "records_output": output_count,
    "records_rejected": reject_count,
    "status": "SUCCESS"
}

# Guardar en tabla de mÃ©tricas
spark.createDataFrame([metrics]).write \
    .mode("append").saveAsTable("monitoring.job_metrics")
```

---

## ğŸ› Troubleshooting

### Problema: El agente no encuentra mis archivos DSX

**SoluciÃ³n**: 
- AsegÃºrate de que el archivo DSX estÃ© en el workspace
- O pega el contenido completo en el chat
- O describe el job en detalle

### Problema: El cÃ³digo generado no funciona

**Revisar**:
1. **Paths**: Ajustar rutas de input/output para tu entorno
2. **Credentials**: Configurar secrets de Databricks
3. **Schema**: Verificar que columnas existan con nombres correctos
4. **Tipos de Datos**: Ajustar casting si necesario

**Pedir ayuda al agente**:
```
@workspace Tengo este error al ejecutar el notebook:
[pegar error]

El cÃ³digo es:
[pegar cÃ³digo relevante]

Â¿CÃ³mo lo soluciono?
```

### Problema: Performance muy lento

**Pedir optimizaciones**:
```
@workspace Este notebook estÃ¡ muy lento:
[pegar cÃ³digo]

Datos:
- Input: 100GB daily
- Cluster: 10 workers, 16GB RAM cada uno
- Tarda: 2 horas (queremos < 30 min)

Â¿QuÃ© optimizaciones recomiendas?
```

El agente sugerirÃ¡:
- Broadcast joins
- Reparticionamiento
- Caching estratÃ©gico
- Configuraciones de Spark
- Ajustes de cluster

### Problema: Resultados diferentes a DataStage

**Investigar con el agente**:
```
@workspace Los resultados no coinciden con DataStage:

DataStage output:
- Count: 10,000
- Sum(amount): 1,000,000

Databricks output:
- Count: 9,500
- Sum(amount): 950,000

Â¿QuÃ© puede estar causando la diferencia?
```

El agente analizarÃ¡:
- Manejo de nulls
- Filtros/constraints
- Joins (inner vs left)
- Orden de operaciones
- Casting de tipos

---

## ğŸ¤ Contribuir

### Agregar Nuevos Patrones

Para extender el agente con nuevos patrones:

1. Agregar documentaciÃ³n en `knowledge/migration-patterns.md`
2. Crear ejemplo en `test-artifacts/`
3. Actualizar `.github-copilot-instructions.md` si necesario

### Reportar Issues

Si encuentras problemas:
1. Describir el job DataStage (o incluir DSX)
2. Compartir el prompt usado
3. Incluir el cÃ³digo generado
4. Describir el problema encontrado
5. Incluir logs de error si aplica

### Sugerir Mejoras

Ideas para mejorar el agente:
- Nuevos tipos de stages DataStage
- Patrones de optimizaciÃ³n adicionales
- Mejor manejo de casos edge
- DocumentaciÃ³n mejorada

---

## ğŸ“– DocumentaciÃ³n Adicional

### GuÃ­as Detalladas
- [GuÃ­a RÃ¡pida de MigraciÃ³n](knowledge/quick-migration-guide.md) - Proceso paso a paso
- [CatÃ¡logo de Componentes DataStage](knowledge/datastage-components.md) - Todos los stages
- [Patrones de MigraciÃ³n](knowledge/migration-patterns.md) - Ejemplos detallados
- [Mejores PrÃ¡cticas Databricks](knowledge/databricks-best-practices.md) - Optimizaciones

### Test Artifacts
- [README de Test Artifacts](test-artifacts/README.md) - DocumentaciÃ³n de jobs de ejemplo

### Recursos Externos
- [Databricks Documentation](https://docs.databricks.com)
- [Delta Lake Documentation](https://docs.delta.io)
- [PySpark API Reference](https://spark.apache.org/docs/latest/api/python/)
- [IBM DataStage Documentation](https://www.ibm.com/docs/en/iis)

---

## ğŸ¯ PrÃ³ximos Pasos

### Para Empezar

1. âœ… **FamiliarÃ­zate**: Lee el [Quick Migration Guide](knowledge/quick-migration-guide.md)
2. âœ… **Prueba**: Migra uno de los test artifacts
3. âœ… **Compara**: Valida el output generado
4. âœ… **Migra**: Empieza con un job DataStage real simple
5. âœ… **Itera**: Mejora y optimiza

### Roadmap

PrÃ³ximas mejoras planeadas:
- [ ] Soporte para DataStage Parallel Jobs
- [ ] IntegraciÃ³n con LineageGraph para dependency mapping
- [ ] Templates de notebooks reutilizables
- [ ] Auto-generaciÃ³n de tests unitarios
- [ ] Comparador automÃ¡tico DataStage vs Databricks output
- [ ] Estimador de costos Databricks

---

## ğŸ“„ Licencia

Este proyecto es un agente educational/evaluativo para GitHub Copilot.

---

## âœ¨ Agradecimientos

Este agente fue creado para facilitar la migraciÃ³n de DataStage a Databricks, aprovechando las capacidades avanzadas de GitHub Copilot para generar cÃ³digo de alta calidad, optimizado y bien documentado.

**Â¡Feliz MigraciÃ³n! ğŸš€**

---

## ğŸ“ Soporte

Para preguntas o ayuda:
1. Consulta la [documentaciÃ³n](knowledge/)
2. Revisa los [test artifacts](test-artifacts/)
3. Pregunta al agente directamente con `@workspace`

**Ejemplo de pregunta al agente**:
```
@workspace Tengo dudas sobre cÃ³mo migrar un Aggregator stage 
con mÃºltiples grouping keys y stage variables. Â¿Puedes explicarme 
el patrÃ³n recomendado con ejemplos?
```
