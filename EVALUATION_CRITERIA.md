# Criterios de Evaluaci√≥n Mejorados

## üìä Pesos Generales

| M√©trica | Peso Anterior | Peso Nuevo | Justificaci√≥n |
|---------|--------------|------------|---------------|
| **Keyword Coverage** | 25% | 15% | Reducido - presencia de palabras no garantiza calidad |
| **Includes Code** | 30% | 15% | Reducido - m√°s importante que el c√≥digo sea correcto |
| **Well Structured** | 20% | 10% | Reducido - la estructura es menos cr√≠tica que la funcionalidad |
| **Category-Specific** | 25% | **60%** | **Aumentado** - evaluaci√≥n profunda seg√∫n el tipo de tarea |

## üéØ Evaluaci√≥n de Migraciones Completas (full_migration)

Para determinar qu√© modelo es mejor en migraciones DSX ‚Üí Databricks, aplicamos **4 niveles de evaluaci√≥n**:

---

### üìå NIVEL 1: CORRECCI√ìN T√âCNICA (40%)

**Objetivo:** Verificar que el c√≥digo generado es t√©cnicamente correcto y funcional.

#### 1.1 Sintaxis V√°lida (10%)
- **M√©todo:** Validaci√≥n con `ast.parse()` de Python
- **Evaluaci√≥n:** `bloques_v√°lidos / total_bloques`
- **Criterio de √©xito:** Todos los bloques de c√≥digo deben parsear sin errores
- **Ejemplo de fallo:**
  ```python
  # Sintaxis inv√°lida - punto y coma en Python
  df = spark.read.csv(path);
  ```

#### 1.2 Schema Fidelity (15%)
- **M√©todo:** Extracci√≥n de columnas del DSX vs columnas en PySpark
- **Evaluaci√≥n:** `columnas_coincidentes / total_columnas_dsx`
- **Criterio de √©xito:** ‚â•80% de columnas del DSX deben aparecer en el c√≥digo
- **Ejemplo DSX:**
  ```xml
  <Column Name="CustomerID" SqlType="INTEGER"/>
  <Column Name="FirstName" SqlType="VARCHAR"/>
  <Column Name="Email" SqlType="VARCHAR"/>
  ```
- **Esperado en PySpark:**
  ```python
  df.select("CustomerID", "FirstName", "Email")
  ```

#### 1.3 Transformaciones Correctas (15%)
- **M√©todo:** Detectar categor√≠as de transformaciones DSX‚ÜíPySpark
- **Categor√≠as evaluadas:**
  - String operations: `trim`, `upper`, `lower`, `concat`
  - Date operations: `datediff`, `date_add`, `current_date`
  - Null handling: `isNull`, `isNotNull`, `coalesce`, `when`
  - Aggregations: `groupBy`, `agg`, `sum`, `count`
- **Evaluaci√≥n:** `categor√≠as_encontradas / 4`
- **Ejemplo DSX:**
  ```datastage
  Trim(Upcase(FirstName)) : " " : Trim(Upcase(LastName))
  ```
- **Esperado en PySpark:**
  ```python
  F.concat(F.trim(F.upper(F.col("FirstName"))), F.lit(" "), F.trim(F.upper(F.col("LastName"))))
  ```

---

### üìå NIVEL 2: COMPLETITUD (30%)

**Objetivo:** Verificar que todos los componentes del DSX fueron migrados.

#### 2.1 Todos los Stages Migrados (15%)
- **M√©todo:** Detectar presencia de operaciones READ + TRANSFORM + WRITE
- **Evaluaci√≥n:** `stages_presentes / 3`
- **Criterio de √©xito:** Los 3 stages deben estar
- **Mapeo DSX ‚Üí PySpark:**
  - `Sequential_File` (Source) ‚Üí `spark.read`
  - `Transformer` ‚Üí `.withColumn`, `.select`, `.filter`
  - `Sequential_File` (Target) ‚Üí `.write`

#### 2.2 Par√°metros Extra√≠dos (10%)
- **M√©todo:** Comparar par√°metros del DSX vs `dbutils.widgets`
- **Evaluaci√≥n:** `par√°metros_migrados / total_par√°metros_dsx`
- **Ejemplo DSX:**
  ```xml
  <Parameter>
    <Property Name="Name">INPUT_FILE_PATH</Property>
    <Property Name="DefaultValue">/data/input/customers.csv</Property>
  </Parameter>
  ```
- **Esperado en PySpark:**
  ```python
  dbutils.widgets.text("INPUT_FILE_PATH", "/data/input/customers.csv")
  INPUT_FILE_PATH = dbutils.widgets.get("INPUT_FILE_PATH")
  ```

#### 2.3 Validaciones Incluidas (5%)
- **M√©todo:** Detectar constraints del DSX convertidos a validaciones PySpark
- **Evaluaci√≥n:** Binario (0% o 5%)
- **Indicadores:** `filter`, `isNotNull`, `isNull`, `constraint`
- **Ejemplo DSX:**
  ```xml
  <Constraint>
    <Property Name="Expression">NOT(IsNull(CustomerID))</Property>
  </Constraint>
  ```
- **Esperado en PySpark:**
  ```python
  df_validated = df.filter(F.col("CustomerID").isNotNull())
  ```

---

### üìå NIVEL 3: BEST PRACTICES (20%)

**Objetivo:** Verificar que el c√≥digo sigue mejores pr√°cticas de Databricks.

#### 3.1 Delta Lake Usage (8%)
- **M√©todo:** Detectar uso de formato Delta
- **Evaluaci√≥n:** 
  - 5% por uso b√°sico de Delta (`format("delta")`)
  - 8% por uso avanzado (+ `OPTIMIZE` o `MERGE`)
- **Ejemplo b√°sico:**
  ```python
  df.write.format("delta").mode("overwrite").save(path)
  ```
- **Ejemplo avanzado:**
  ```python
  df.write.format("delta").mode("overwrite").save(path)
  spark.sql(f"OPTIMIZE delta.`{path}` ZORDER BY (customer_id)")
  ```

#### 3.2 Partitioning Strategy (6%)
- **M√©todo:** Detectar estrategia de particionamiento
- **Evaluaci√≥n:** 
  - 6% por `partitionBy`
  - 3% por `repartition` o `coalesce`
- **Ejemplo:**
  ```python
  df.write.partitionBy("year", "month").format("delta").save(path)
  ```

#### 3.3 Error Handling (6%)
- **M√©todo:** Detectar manejo de errores
- **Indicadores:** `try:`, `except`, `raise`, `assert`, `logger`
- **Evaluaci√≥n:**
  - 6% si ‚â•2 indicadores
  - 3% si 1 indicador
- **Ejemplo:**
  ```python
  try:
      df = spark.read.csv(path)
  except Exception as e:
      logger.error(f"Error reading file: {e}")
      raise
  ```

---

### üìå NIVEL 4: CALIDAD (10%)

**Objetivo:** Evaluar documentaci√≥n y estructura del notebook.

#### 4.1 Documentaci√≥n (5%)
- **Indicadores:** `# MAGIC %md`, `##`, `"""`, `'''`
- **Evaluaci√≥n:**
  - 5% si ‚â•3 indicadores
  - 3% si 2 indicadores
  - 2% si 1 indicador
- **Ejemplo:**
  ```python
  # MAGIC %md
  # MAGIC ## 1. Read Customer Data
  # MAGIC 
  # MAGIC Este notebook procesa datos de clientes...
  
  """
  Lee archivo CSV de clientes y aplica transformaciones de limpieza
  """
  df = spark.read.csv(path)
  ```

#### 4.2 Estructura Notebook (5%)
- **M√©todo:** Detectar formato de notebook Databricks
- **Evaluaci√≥n:**
  - 5% por `# Databricks notebook source`
  - 3% por `# MAGIC %md` o `# COMMAND`
- **Ejemplo:**
  ```python
  # Databricks notebook source
  # MAGIC %md
  # MAGIC # Customer ETL Migration
  # MAGIC **DSX Source:** Simple_Customer_ETL.dsx
  
  # COMMAND ----------
  
  # Import libraries
  from pyspark.sql import functions as F
  ```

---

## üèÜ C√≥mo Determinar el Mejor Modelo

### Criterios de Selecci√≥n

1. **Score Overall ‚â• 90%** en migraciones completas
2. **Sintaxis v√°lida = 100%** (todos los bloques parsean)
3. **Schema fidelity ‚â• 80%** (preserva columnas del DSX)
4. **Completitud = 100%** (todos los stages migrados)
5. **Best practices ‚â• 70%** (usa Delta Lake + partitioning)

### Matriz de Comparaci√≥n

| Modelo | Overall | Sintaxis | Schema | Completitud | Best Practices | Calidad |
|--------|---------|----------|--------|-------------|----------------|---------|
| gpt-5.2-codex | ? | ? | ? | ? | ? | ? |
| gpt-5.1-codex | ? | ? | ? | ? | ? | ? |

> **Nota:** Ejecuta `python evaluate_agent.py --mode azure-entra --models gpt-5.2-codex gpt-5.1-codex` para llenar esta tabla.

---

## üìà Ejemplo de Reporte Detallado

```
  üîç  DESGLOSE DETALLADO: MIGRACIONES COMPLETAS (full_migration)
================================================================================

  üìä  Modelo: gpt-5.2-codex
  ----------------------------------------------------------------------------

    M√©trica                              Promedio        Peso
    ------------------------------------------------------------
    NIVEL 1: CORRECCI√ìN T√âCNICA                           40%
      ‚îî‚îÄ Sintaxis v√°lida                   100.0%      (10%)
      ‚îî‚îÄ Schema fidelity                    87.5%      (15%)
      ‚îî‚îÄ Transformaciones correctas         95.0%      (15%)

    NIVEL 2: COMPLETITUD                                  30%
      ‚îî‚îÄ Todos los stages                  100.0%      (15%)
      ‚îî‚îÄ Par√°metros extra√≠dos               85.0%      (10%)
      ‚îî‚îÄ Validaciones                      100.0%       (5%)

    NIVEL 3: BEST PRACTICES                               20%
      ‚îî‚îÄ Delta Lake                         80.0%       (8%)
      ‚îî‚îÄ Partitioning                       50.0%       (6%)
      ‚îî‚îÄ Error handling                     33.3%       (6%)

    NIVEL 4: CALIDAD                                      10%
      ‚îî‚îÄ Documentaci√≥n                      80.0%       (5%)
      ‚îî‚îÄ Estructura notebook               100.0%       (5%)

    ------------------------------------------------------------
    OVERALL (full_migration)                92.3%        100%
```

---

## üöÄ Pr√≥ximos Pasos

1. **Ejecutar evaluaci√≥n completa:**
   ```powershell
   python evaluate_agent.py --mode azure-entra --models gpt-5.2-codex gpt-5.1-codex
   ```

2. **Comparar con/sin knowledge base:**
   ```powershell
   # Con knowledge base (default)
   python evaluate_agent.py --mode azure-entra --models gpt-5.1-codex
   
   # Sin knowledge base
   python evaluate_agent.py --mode azure-entra --models gpt-5.1-codex --no-knowledge
   ```

3. **Analizar casos espec√≠ficos:**
   - Revisar `evaluation_report.json` ‚Üí `details` ‚Üí casos con score < 80%
   - Identificar patrones de error (sintaxis, schema, transformaciones)
   - Iterar sobre knowledge base o prompts

4. **Validar notebooks generados:**
   - Copiar c√≥digo de `response` del JSON
   - Ejecutar en Databricks workspace
   - Verificar que produce output correcto
